{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export materiall from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.svg\n",
      "['A3212.png', 'A2122.png']\n",
      "10.svg\n",
      "['A1.png', 'A2121_1_.png', 'A323.png']\n",
      "11.svg\n",
      "['A1.png', 'A2121_1_.png', 'A313.png']\n",
      "2.svg\n",
      "['A2121.png', 'A4.png', 'A324.png']\n",
      "3.svg\n",
      "['A312.png']\n",
      "4.svg\n",
      "['A2211.png', 'A311.png']\n",
      "5.svg\n",
      "['A3211.png', 'A2212.png']\n",
      "6.svg\n",
      "['A311.png', 'A2112.png']\n",
      "7.svg\n",
      "['A2121.png', 'A324.png']\n",
      "8.svg\n",
      "['A2121.png', 'A311.png']\n",
      "9.svg\n",
      "['A2121.png']\n"
     ]
    }
   ],
   "source": [
    "## export layers to dir named after file\n",
    "import os\n",
    "for file in sorted(os.listdir('images')):\n",
    "    base, ext = os.path.splitext(file)\n",
    "    if ext == '.svg' and base != 'test' and base != 'stack':\n",
    "        print(file)\n",
    "        os.system(\"./export_svg.sh %s\" % file)\n",
    "        print(os.listdir('images/m_%s' % base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_layers(prefix='m_', target='material', image_dir='images'):\n",
    "    \"\"\"\n",
    "    Collect layers in separate dirs into material\n",
    "    Extend name if necessary\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import shutil\n",
    "    from tools.image_process import cleanName\n",
    "    \n",
    "    if os.path.exists(target):\n",
    "        files = glob.glob(target+'/*')\n",
    "        for file in files:\n",
    "            os.remove(file)\n",
    "    else:\n",
    "        os.system('mkdir '+target)\n",
    "\n",
    "    for d_ in sorted(os.listdir(image_dir)):\n",
    "        d = image_dir + '/' + d_\n",
    "        if os.path.isdir(d) and d_.startswith(prefix):\n",
    "            print(d)\n",
    "            for m in os.listdir(d):\n",
    "                print('  %s' % m)\n",
    "                if m in os.listdir(target):\n",
    "                    base, ext = os.path.splitext(m)\n",
    "                    base = cleanName(base)\n",
    "                    num = len(glob.glob('%s/%s*.png' % (target,\n",
    "                                                        base)))\n",
    "                    new_m = '%s_(%s)%s' % (base, num, ext)\n",
    "                else:\n",
    "                    new_m = cleanName()\n",
    "                shutil.copy(d+'/'+m, target+'/'+new_m)\n",
    "            # os.rmdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/m_1\n",
      "  A3212.png\n",
      "  A2122.png\n",
      "images/m_10\n",
      "  A1.png\n",
      "  A2121.png\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/m_10/A2121.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/m_10/A2121.png' -> 'material/A2121.png'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2bde25e333dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgroup_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-6d8e655e745e>\u001b[0m in \u001b[0;36mgroup_layers\u001b[0;34m(prefix, target, image_dir)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mnew_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnew_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/m_10/A2121.png'"
     ]
    }
   ],
   "source": [
    "group_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weird!\n",
    "# every time use svg-objects-export.py to export a .svg, or use parse in xml to read a .svg, the objects in this image will move  to the right for a random length, but it won't affect the next read or parse, and it won't affect the appearance of exported .png files\n",
    "# also, use parse, export or even open the .svg in the browser, the layers will be stacked into one layer on the very top\n",
    "# seems a problem with minidom or inkscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.image_process import getLayerNames, checkLayerNames, image2feature\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/1.svg\n",
      "['A2122', 'A3212']\n",
      "[2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "images/10.svg\n",
      "['A1', 'A2121_1_', 'A323']\n",
      "[3, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "images/11.svg\n",
      "['A1', 'A2121_1_', 'A313']\n",
      "[3, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "images/2.svg\n",
      "['A4', 'A2121', 'A324']\n",
      "[3, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "images/3.svg\n",
      "['A4', 'A2122', 'A312']\n",
      "[3, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "images/4.svg\n",
      "['A2211', 'A311']\n",
      "[2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "images/5.svg\n",
      "['A2212', 'A3211']\n",
      "[2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "images/6.svg\n",
      "['A2112', 'A311']\n",
      "[2, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "images/7.svg\n",
      "['A2121', 'A324']\n",
      "[2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "images/8.svg\n",
      "['A311', 'A2121']\n",
      "[2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "images/9.svg\n",
      "['A2121']\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for fileName in sorted(glob.glob('images/*.svg')):\n",
    "    # base, ext = os.path.splitext(fileName)\n",
    "    # if ext == '.svg' and base != 'test' and base != 'stack':\n",
    "    if 'test' in fileName or 'stack' in fileName:\n",
    "        continue\n",
    "    print(fileName)\n",
    "    # print(get_id_list(fileName))\n",
    "    names = getLayerNames(fileName)\n",
    "    checkLayerNames(names)\n",
    "    print(names)\n",
    "    print(image2feature(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caveats\n",
    "# The first <image> element in a <g> is the shadow, namely the extra .png file in the dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/1.txt\n",
      "A man looks at his chart with his back.\n",
      "\n",
      "['man.n.01', 'look.v.01', 'chart.n.01', 'back.n.01']\n",
      "text/10.txt\n",
      "A man walks past a web Icon\n",
      "['man.n.01', 'walk.v.01', 'past', 'web.n.01', 'icon.n.01']\n",
      "text/11.txt\n",
      "A man and a woman are interacting\n",
      "['man.n.01', 'woman.n.01', 'be.v.01', 'interact.v.01']\n",
      "text/2.txt\n",
      "A man demonstrates the chart.\n",
      "['man.n.01', 'show.v.01', 'chart.n.01']\n",
      "text/3.txt\n",
      "A man and a woman play circles with compasses.\n",
      "['man.n.01', 'woman.n.01', 'play.n.01', 'circle.n.01', 'compass.n.01']\n",
      "text/4.txt\n",
      "A girl was leaning against a car.\n",
      "['girl.n.01', 'be.v.01', 'lean.v.01', 'car.n.01']\n",
      "text/5.txt\n",
      "A girl was standing on the edge of the city.\n",
      "['girl.n.01', 'be.v.01', 'stand.v.01', 'edge.n.01', 'city.n.01']\n",
      "text/6.txt\n",
      "A man is cleaning his computer.\n",
      "['man.n.01', 'be.v.01', 'clean.v.01', 'computer.n.01']\n",
      "text/7.txt\n",
      "A boy is demonstrating a form.\n",
      "['male_child.n.01', 'be.v.01', 'show.v.01', 'form.n.01']\n",
      "text/8.txt\n",
      "There are three trademarks around a person\n",
      "['be.v.01', 'three', 'hallmark.n.01', 'around', 'person.n.01']\n",
      "text/9.txt\n",
      "Mobile phones and charts\n",
      "['mobile.n.01', 'telephone.n.01', 'chart.n.01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tools.text_process import LemmaTokenizer\n",
    "tokenizer = LemmaTokenizer()\n",
    "for fileName in sorted(glob.glob('text/*.txt')):\n",
    "    print(fileName)\n",
    "    with open(fileName, 'r') as f:\n",
    "        sent = f.read()\n",
    "        print(sent)\n",
    "        print(tokenizer(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['A man is lying on the sofa.',\n",
    "             'A man is sitting next to a computer.',\n",
    "             'A man is presenting a chart. The light is on. we',\n",
    "             'A woman is standing next to a bucket.',\n",
    "             \"It's a deer in a sock\",\n",
    "             'A christmas tree with presents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man.n.01', 'be.v.01', 'lie.v.01', 'sofa.n.01']\n",
      "['man.n.01', 'be.v.01', 'sit.v.01', 'following.s.02', 'computer.n.01']\n",
      "['man.n.01', 'be.v.01', 'show.v.01', 'chart.n.01', 'light.n.01', 'be.v.01']\n",
      "['woman.n.01', 'be.v.01', 'stand.v.01', 'following.s.02', 'bucket.n.01']\n",
      "['deer.n.01', 'sock.n.01']\n",
      "['christmas.n.01', 'tree.n.01', 'present.n.01']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/miniconda2/envs/text2scene/lib/python3.7/site-packages/ipykernel_launcher.py:43: UserWarning: \"'s\" does not belong to any synsets.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LemmaTokenizer()\n",
    "sentences = []\n",
    "for sentence in test_text:\n",
    "    print(tokenizer(sentence))\n",
    "    sentences.append(tokenizer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stanford POS tagger. Same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "_path = 'models'\n",
    "_path_to_model = _path + '/stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n",
    "_path_to_jar = _path + '/stanford-postagger-2018-10-16/stanford-postagger.jar'\n",
    "st = StanfordPOSTagger(model_filename=_path_to_model,\n",
    "                       path_to_jar=_path_to_jar)\n",
    "text = \"The quick brown fox jumps over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('lying', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('sofa', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('lying', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('sofa', 'NN'), ('.', '.')]\n",
      "---\n",
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('next', 'JJ'), ('to', 'TO'), ('a', 'DT'), ('computer', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('next', 'JJ'), ('to', 'TO'), ('a', 'DT'), ('computer', 'NN'), ('.', '.')]\n",
      "---\n",
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('presenting', 'VBG'), ('a', 'DT'), ('chart', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('man', 'NN'), ('is', 'VBZ'), ('presenting', 'VBG'), ('a', 'DT'), ('chart', 'NN'), ('.', '.')]\n",
      "---\n",
      "[('A', 'DT'), ('woman', 'NN'), ('is', 'VBZ'), ('standing', 'VBG'), ('next', 'JJ'), ('to', 'TO'), ('a', 'DT'), ('bucket', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('woman', 'NN'), ('is', 'VBZ'), ('standing', 'VBG'), ('next', 'JJ'), ('to', 'TO'), ('a', 'DT'), ('bucket', 'NN'), ('.', '.')]\n",
      "---\n",
      "[('A', 'DT'), ('deer', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('sock', 'NN')]\n",
      "[('A', 'DT'), ('deer', 'NN'), ('in', 'IN'), ('a', 'DT'), ('sock', 'NN')]\n",
      "---\n",
      "[('A', 'DT'), ('christmas', 'NN'), ('tree', 'NN'), ('with', 'IN'), ('presents', 'NNS')]\n",
      "[('A', 'DT'), ('christmas', 'NN'), ('tree', 'NN'), ('with', 'IN'), ('presents', 'NNS')]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for sent in test_text:\n",
    "    tags = st.tag(word_tokenize(sent))\n",
    "    print(tags)\n",
    "    print(pos_tag(word_tokenize(sent)))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple wsd. not stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default lesk:  Synset('man.n.01')\n",
      "Default lesk:  Synset('world.n.08')\n",
      "Simple_lesk: Synset('world.n.08')\n",
      "Simple_lesk: Synset('world.n.08')\n",
      "----\n",
      "Synset('equal.v.01')\n",
      "Synset('embody.v.02')\n",
      "Synset('exist.v.01')\n",
      "Synset('be.v.03')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "from pywsd.lesk import simple_lesk\n",
    "\n",
    "# Incorrect usage\n",
    "# print('Default lesk: ', lesk('A man is sitting next to a computer', 'man', wn.NOUN))\n",
    "# should use tokenzier first, see source code\n",
    "print('Default lesk: ', lesk(word_tokenize('A man is sitting next to a computer'), 'man', wn.NOUN))\n",
    "# a different intepretation\n",
    "print('Default lesk: ', lesk(word_tokenize('A man is lying on the sofa.'), 'man', wn.NOUN))\n",
    "print('Simple_lesk:', simple_lesk('A man is lying on the sofa.', 'man', wn.NOUN))\n",
    "print('Simple_lesk:', simple_lesk('A man is sitting next to a computer', 'man', wn.NOUN))\n",
    "\n",
    "# another example - results all different\n",
    "print('----')\n",
    "print(lesk(word_tokenize('A man is sitting next to a computer'), 'be', wn.VERB))\n",
    "print(lesk(word_tokenize('A man is lying on the sofa.'), 'be', wn.VERB))\n",
    "print(simple_lesk('A man is lying on the sofa.', 'be', wn.VERB))\n",
    "print(simple_lesk('A man is sitting next to a computer', 'be', wn.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.33647224 2.25276297 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         2.25276297 2.25276297\n",
      "  0.         0.         1.55961579 1.55961579 0.         0.\n",
      "  0.         0.         0.         0.         2.25276297 0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [1.33647224 0.         0.         2.25276297 0.         0.\n",
      "  0.         0.         0.         0.         2.25276297 0.\n",
      "  0.         1.84729786 0.         2.25276297 0.         0.\n",
      "  0.         0.         1.55961579 1.55961579 0.         0.\n",
      "  0.         2.25276297 2.25276297 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [2.2628442  0.         2.25276297 0.         0.         0.\n",
      "  2.25276297 2.25276297 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  2.25276297 2.25276297 1.55961579 1.55961579 0.         2.25276297\n",
      "  2.25276297 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [1.33647224 0.         0.         0.         2.25276297 2.25276297\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.84729786 2.25276297 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         2.25276297\n",
      "  2.25276297 0.         0.         2.25276297 2.25276297]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         2.25276297\n",
      "  2.25276297 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         2.25276297 0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         2.25276297 2.25276297 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         2.25276297 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.25276297 2.25276297 0.         0.        ]]\n",
      "{'man.n.01': 20, 'be.v.01': 0, 'lie.v.01': 16, 'sofa.n.01': 28, 'man.n.01 be.v.01': 21, 'be.v.01 lie.v.01': 1, 'lie.v.01 sofa.n.01': 17, 'sit.v.01': 25, 'following.s.02': 13, 'computer.n.01': 10, 'be.v.01 sit.v.01': 3, 'sit.v.01 following.s.02': 26, 'following.s.02 computer.n.01': 15, 'show.v.01': 23, 'chart.n.01': 6, 'light.n.01': 18, 'be.v.01 show.v.01': 2, 'show.v.01 chart.n.01': 24, 'chart.n.01 light.n.01': 7, 'light.n.01 be.v.01': 19, 'woman.n.01': 33, 'stand.v.01': 29, 'bucket.n.01': 5, 'woman.n.01 be.v.01': 34, 'be.v.01 stand.v.01': 4, 'stand.v.01 following.s.02': 30, 'following.s.02 bucket.n.01': 14, 'deer.n.01': 11, 'sock.n.01': 27, 'deer.n.01 sock.n.01': 12, 'christmas.n.01': 8, 'tree.n.01': 31, 'present.n.01': 22, 'christmas.n.01 tree.n.01': 9, 'tree.n.01 present.n.01': 32}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                             norm=None,\n",
    "                             sublinear_tf=True,\n",
    "                             stop_words=[],\n",
    "                             lowercase=False,\n",
    "                             tokenizer=lambda l: l)\n",
    "print(vectorizer.fit_transform(sentences).toarray())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity between category keywords and the description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2num_size(size):\n",
    "    assert type(size) is str\n",
    "    return int(float(size.strip('pt')))\n",
    "    \n",
    "def get_size(file):\n",
    "    \"\"\"\n",
    "    Get the width and height of an image\n",
    "    \n",
    "    .svg:\n",
    "        use xml's parse\n",
    "        By check the 'viewBox' attribute in the 'svg' tag\n",
    "    \n",
    "    .png:\n",
    "        use PIL\n",
    "    \"\"\"\n",
    "    \n",
    "    basename, ext = os.path.splitext(file)\n",
    "    if ext == '.svg':   \n",
    "        from xml.dom.minidom import parse\n",
    "        doc = parse(file)\n",
    "        # search svg element\n",
    "        image_list = doc.getElementsByTagName('svg')\n",
    "        assert(image_list), 'no svg element found!'\n",
    "        assert(len(image_list) == 1), file\n",
    "        img = image_list[0]\n",
    "        assert(img.hasAttribute('viewBox'))\n",
    "        width, height = img.getAttribute('viewBox').split()[2:]\n",
    "        width, height = (str2num_size(width), str2num_size(height))\n",
    "        # try search image element, then g element\n",
    "#     try:\n",
    "#         assert image_list\n",
    "#     except AssertionError:\n",
    "#         image_list = doc.getElementsByTagName('svg')\n",
    "#         assert image_list\n",
    "#         assert image_list[0].hasAttribute('width')\n",
    "#     assert(len(image_list) == 1), svg_file\n",
    "#     ## if multiple images, size is the maximum size in either direction        \n",
    "    elif ext == '.png':\n",
    "        from PIL import Image\n",
    "        width, height = Image.open(file).size\n",
    "\n",
    "    return (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_svgs(file_list, opt_file=None, canvas_size=None):\n",
    " \n",
    "    import cairosvg\n",
    "    from svgutils.compose import Figure, Image #,SVG\n",
    "    \n",
    "    if not opt_file:\n",
    "        opt_file = 'stack.svg'\n",
    "        \n",
    "    if canvas_size:\n",
    "        canvas_w, canvas_h = canvas_size\n",
    "    else:\n",
    "        canvas_w, canvas_h = 0, 0\n",
    "        for file in file_list:\n",
    "            width, height = get_size(file)\n",
    "            if width > canvas_w: canvas_w = width\n",
    "            if height > canvas_h: canvas_h = height\n",
    "    print('Canvas size:', (canvas_w, canvas_h))\n",
    "    \n",
    "    # if svg, convert to png first\n",
    "    file_list_png = []\n",
    "    for file in file_list:\n",
    "        basename, ext = os.path.splitext(file)\n",
    "        if ext == '.svg':\n",
    "            png_file = basename + '.png'\n",
    "            cairosvg.svg2png(url=file,\n",
    "                             write_to=png_file)\n",
    "            file_list_png.append(png_file)\n",
    "        elif ext == '.png':\n",
    "            file_list_png.append(file)\n",
    "        else:\n",
    "            raise ValueError('File type not availale!')\n",
    "    \n",
    "    image_list = []\n",
    "    # \n",
    "    for file in file_list_png:\n",
    "        print('File:', file)\n",
    "        width, height = get_size(file)\n",
    "        img = Image(width, height, file)\n",
    "        img.move(int((canvas_w-width)/2),\n",
    "                 int((canvas_h-height)/2))\n",
    "        image_list.append(img)\n",
    "    \n",
    "        \n",
    "    Figure(canvas_w, canvas_h, *image_list).save(opt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas size: (1114, 786)\n",
      "File: svg-objects-export/A-1.png\n",
      "File: svg-objects-export/A-2-1-2-1.png\n",
      "File: svg-objects-export/A-3-1.png\n"
     ]
    }
   ],
   "source": [
    "stack_svgs(['svg-objects-export/A-1.png', \n",
    "            'svg-objects-export/A-2-1-2-1.png', \n",
    "            'svg-objects-export/A-3-1.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas size: (1145, 816)\n",
      "File: material/背景4.png\n",
      "File: material/123.png\n",
      "File: material/生活方式3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/miniconda2/envs/text2scene/lib/python3.7/site-packages/cairosvg/parser.py:416: UserWarning: No tag with id=未命名的渐变_12-2 found.\n",
      "  warnings.warn('No tag with id={} found.'.format(element_id))\n",
      "/Users/dongjustin/miniconda2/envs/text2scene/lib/python3.7/site-packages/cairosvg/parser.py:416: UserWarning: No tag with id=未命名的渐变_12-3 found.\n",
      "  warnings.warn('No tag with id={} found.'.format(element_id))\n",
      "/Users/dongjustin/miniconda2/envs/text2scene/lib/python3.7/site-packages/cairosvg/parser.py:416: UserWarning: No tag with id=未命名的渐变_12-4 found.\n",
      "  warnings.warn('No tag with id={} found.'.format(element_id))\n"
     ]
    }
   ],
   "source": [
    "stack_svgs(['material/背景4.svg', \n",
    "            'material/123.svg', \n",
    "            'material/生活方式3.svg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a tool to stack two svgs:\n",
    "### put <g> altogether, then for each elememt, add attribute recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ValueError: material/124.svg\n",
    "## issue of cairosvg converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = parse('SB.svg')\n",
    "# ele = [c for c in doc.childNodes if c.nodeType == 1]\n",
    "# assert(len(ele) == 1)\n",
    "# [n.getAttribute('id') for n in ele[0].childNodes if n.nodeType==1 and n.tagName=='g']\n",
    "# [g.getAttribute('id') for g in doc.getElementsByTagName('g') if g.hasAttribute('id')]\n",
    "# id_list = [g.getAttribute('id') for g in doc.getElementsByTagName('g') if g.hasAttribute('id')]\n",
    "# assert(id_list)\n",
    "\n",
    "# get the tagname: element.tagName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order may be reversed, that's weird\n",
    "# at least. background must be at the bottom\n",
    "# but what if there are only person and surronding\n",
    "\n",
    "# it's reversed\n",
    "# because the first object is at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DOM Element: image at 0x112681cc0>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.getElementsByTagName('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_x31__x5F_1_x5F_1']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[g.getAttribute('id') for g in doc.getElementsByTagName('*') if g.hasAttribute('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2scene",
   "language": "python",
   "name": "text2scene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
