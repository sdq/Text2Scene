{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from scipy import sparse\n",
    "\n",
    "from tools.text_process import TfidfEncoder\n",
    "from tools.image_process import getLayerNames, CategEncoder\n",
    "from tools.joint_process import SimiEncoder\n",
    "from models.vectorizer import getVectorizer\n",
    "\n",
    "# random image generator, subject to rules\n",
    "from tools.generator import ranGenLayer\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, img_dir='images', txt_dir='text'):\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_dir = txt_dir\n",
    "        # self.tokenizer = LemmaTokenizer()\n",
    "        # this operation will process all the text and train a vectorizer\n",
    "        # so we have double processed the text here\n",
    "#         self.vectorizer = getVectorizer()\n",
    "        \n",
    "#         self.vocab_, _ = zip(*sorted(self.vectorizer.vocabulary_.items(), key=lambda x:x[::-1]))\n",
    "        self.img_encoder = CategEncoder()\n",
    "        self.txt_encoder = TfidfEncoder()\n",
    "        # self.img_encoder = CategEncoder(self.txt_encoder.vocab_) \n",
    "        \n",
    "        self.joint_encoder = SimiEncoder(self.img_encoder,\n",
    "                                         self.txt_encoder)\n",
    "        \n",
    "        # set features\n",
    "        self.features_ = []\n",
    "        self.features_.extend(self.txt_encoder.vocab_) # text features\n",
    "        self.features_.extend(self.img_encoder.features_) # image features\n",
    "        self.features_.extend(self.joint_encoder.features_)\n",
    "        \n",
    "#         self.features_.extend(['_S_%s_%s_' % (k, t) for k in self.encoder.srd_categ for t in self.vocab_]) # joint features\n",
    "#         self.features_.extend(['_P_%s_%s_' % (k, t) for k in self.encoder.prs_categ for t in self.vocab_]) # joint features\n",
    "      \n",
    "    def getOneLayerSent(self, txt_name=None, img_name=None,\n",
    "                              ran_txt=False, ran_img=False,\n",
    "                              fake_img=False):\n",
    "        ##### preprocess\n",
    "        ## text\n",
    "        if ran_txt:\n",
    "            all_txt = glob.glob(self.txt_dir+'/*.txt')\n",
    "            # rule out current text\n",
    "            all_txt.remove(txt_name)\n",
    "            txt_name = random.choice(all_txt)\n",
    "        else:\n",
    "            assert(txt_name)\n",
    "            \n",
    "        with open(txt_name, 'r') as f:\n",
    "            # orig_sent = f.read()\n",
    "            # sent = self.tokenizer(orig_sent)\n",
    "            sent = f.read()\n",
    "            \n",
    "        ## image\n",
    "        if ran_img:\n",
    "            assert img_name\n",
    "            assert not fake_img\n",
    "            all_img = glob.glob(self.img_dir+'/*.svg')\n",
    "            all_img.remove(img_name)\n",
    "            img_name = random.choice(all_img)\n",
    "            layers = getLayerNames(img_name)\n",
    "        elif fake_img:\n",
    "            assert img_name is None\n",
    "            assert not ran_img\n",
    "            layers = ranGenLayer()\n",
    "        else:\n",
    "            layers = getLayerNames(img_name)\n",
    "            \n",
    "        return layers, sent\n",
    "    \n",
    "#     def __flattenSparse(self, matrix):\n",
    "#         return matrix.toarray().flatten()\n",
    "        \n",
    "    def __getEmbed(self, **kwargs):\n",
    "        \n",
    "        layers, sent = self.getOneLayerSent(**kwargs)\n",
    "        \n",
    "        # tofeature\n",
    "        # txt_embed = self.vectorizer.transform([sent]).toarray()[0]\n",
    "        txt_embed = self.txt_encoder.encode(sent)\n",
    "        # img_embed = self.encoder.encode(layers)\n",
    "        img_embed = self.img_encoder.encode(layers)\n",
    "        # joint_embed = self.__flattenSparse(getCrossSimi(layers, sent, self.vocab_))\n",
    "        joint_embed = self.joint_encoder.encode(layers, sent)\n",
    "        \n",
    "        return np.hstack([txt_embed, img_embed, joint_embed])        \n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        img_name = '%s/%i.svg' % (self.img_dir, ind+1)\n",
    "        txt_name = '%s/%i.txt' % (self.txt_dir, ind+1)\n",
    "        \n",
    "        # triplets\n",
    "        triplets = []\n",
    "        # true match\n",
    "        triplets.append(self.__getEmbed(txt_name=txt_name,\n",
    "                                        img_name=img_name))\n",
    "        # fake image\n",
    "        triplets.append(self.__getEmbed(txt_name=txt_name,\n",
    "                                        fake_img=True))\n",
    "        # mismatched text\n",
    "        triplets.append(self.__getEmbed(img_name=img_name,\n",
    "                                        txt_name=txt_name,\n",
    "                                        ran_txt=True))\n",
    "        # mismatched image\n",
    "        triplets.append(self.__getEmbed(img_name=img_name,\n",
    "                                        txt_name=txt_name,\n",
    "                                        ran_img=True))\n",
    "        \n",
    "        xs = np.vstack(triplets)\n",
    "        \n",
    "        # ys\n",
    "        ys = np.array([1,0,0,0]).reshape(-1,1)\n",
    "        \n",
    "        return sparse.csr_matrix(np.hstack([xs, ys]))\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(glob.glob(self.img_dir+'/*.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: sideways with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: grid with tag a does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: cell with tag r does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: something with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features:  6398\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TfidfEncoder' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e19b635336e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# features: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e19b635336e9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# features: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-36480322e10c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# true match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         triplets.append(self.__getEmbed(txt_name=txt_name,\n\u001b[0;32m--> 100\u001b[0;31m                                         img_name=img_name))\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# fake image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         triplets.append(self.__getEmbed(txt_name=txt_name,\n",
      "\u001b[0;32m<ipython-input-1-36480322e10c>\u001b[0m in \u001b[0;36m__getEmbed\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# tofeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# txt_embed = self.vectorizer.transform([sent]).toarray()[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtxt_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;31m# img_embed = self.encoder.encode(layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mimg_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfEncoder' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "print('# features: ', len(dataset.features_))\n",
    "data = sparse.vstack([dataset[i] for i in range(len(dataset))])\n",
    "X, y = data[:,:-1], data[:,-1]\n",
    "y = y.toarray().flatten()\n",
    "print('data shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2112', 'A311']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'getNestedKeyWithCode' from 'tools.common' (/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/common.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5b08df7f86dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                        img_name='images/6.svg')\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetNestedKeyWithCode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetNestedKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msurrouding_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetNestedKeyWithCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrouding_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'getNestedKeyWithCode' from 'tools.common' (/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/common.py)"
     ]
    }
   ],
   "source": [
    "layers, sent = dataset.getOneLayerSent(txt_name='text/1.txt',\n",
    "                                       img_name='images/6.svg')\n",
    "print(layers)\n",
    "from tools.common import getNestedKeyWithCode, getNestedKey\n",
    "from rules.category import surrouding_dict, person_dict\n",
    "print(getNestedKeyWithCode(surrouding_dict, [1,1,2]))\n",
    "print(getNestedKeyWithCode(person_dict, [1,1]))\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front.n.01 : the side that is forward or prominent\n",
      "battlefront.n.01 : the line along which opposing armies face each other\n",
      "front.n.03 : the outward appearance of a person\n",
      "front.n.04 : the side that is seen or that goes first\n",
      "front_man.n.01 : a person used as a cover for some questionable activity\n",
      "front.n.06 : a sphere of activity involving effort\n",
      "front.n.07 : (meteorology) the atmospheric phenomenon created at the boundary between two different air masses\n",
      "presence.n.02 : the immediate proximity of someone or something\n",
      "front.n.09 : the part of something that is nearest to the normal viewer\n",
      "movement.n.04 : a group of people with a common ideology who try together to achieve certain general goals\n",
      "front.v.01 : be oriented in a certain direction, often with respect to another reference point; be opposite to\n",
      "front.v.02 : confront bodily\n",
      "front.a.01 : relating to or located in the front\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for syn in wn.synsets('front'):\n",
    "    print(syn.name(),':', syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WordNetError",
     "evalue": "Computing the lch similarity requires Synset('stand.v.01') and Synset('stand.n.02') to have the same part of speech.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd7b921613b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m wn.lch_similarity(wn.synset('stand.v.01'),\n\u001b[0;32m----> 2\u001b[0;31m                   wn.synset('stand.n.02'))\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlch_similarity\u001b[0;34m(self, synset1, synset2, verbose, simulate_root)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlch_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulate_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlch_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulate_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0mlch_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlch_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/text2scene/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlch_similarity\u001b[0;34m(self, other, verbose, simulate_root)\u001b[0m\n\u001b[1;32m    864\u001b[0m             raise WordNetError(\n\u001b[1;32m    865\u001b[0m                 \u001b[0;34m'Computing the lch similarity requires '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0;34m'%s and %s to have the same part of speech.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m             )\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWordNetError\u001b[0m: Computing the lch similarity requires Synset('stand.v.01') and Synset('stand.n.02') to have the same part of speech."
     ]
    }
   ],
   "source": [
    "wn.lch_similarity(wn.synset('stand.v.01'),\n",
    "                  wn.synset('stand.n.02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 4)\t1.3350010667323402\n",
      "  (1, 14)\t1.2396908869280152\n",
      "  (1, 45)\t1.8718021769015913\n",
      "  (1, 50)\t1.4403615823901665\n",
      "  (3, 4)\t1.2396908869280152\n",
      "  (3, 14)\t1.1526795099383855\n",
      "  (3, 50)\t1.3350010667323402\n",
      "  (17, 45)\t1.8718021769015913\n",
      "  (18, 4)\t1.3350010667323402\n",
      "  (18, 14)\t1.6916760106710724\n",
      "  (18, 50)\t1.3350010667323402\n"
     ]
    }
   ],
   "source": [
    "from tools.image_process import getCrossSimi\n",
    "print(getCrossSimi(layers, sent, dataset.vocab_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete\n",
      "appliance\n",
      "interact\n",
      "office\n",
      "--\n",
      "back.n.01\n",
      "chart.n.01\n",
      "look.v.01\n",
      "man.n.01\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(dataset.categ_[1])\n",
    "print(dataset.categ_[3])\n",
    "print(dataset.categ_[17])\n",
    "print(dataset.categ_[18])\n",
    "print('--')\n",
    "print(dataset.vocab_[4])\n",
    "print(dataset.vocab_[14])\n",
    "print(dataset.vocab_[45])\n",
    "print(dataset.vocab_[50])\n",
    "# The problem is, bigrams will never contribute to the cross similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train:  151\n",
      "# test:  17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 0.5, 1: 1}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(# random_state=0,\n",
    "                         solver='liblinear',\n",
    "                         class_weight={1: 1, 0:0.5},\n",
    "                         penalty='l1', #'l2' use l1 to learn sparsely\n",
    "                         C=1.0,\n",
    "                         max_iter=100)\n",
    "\n",
    "ind_test = int(X.shape[0] * 0.9)\n",
    "print('# train: ', ind_test)\n",
    "print('# test: ', X.shape[0] - ind_test)\n",
    "clf.fit(X[:ind_test], y[:ind_test])\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7647058823529411\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Accuracy: ', clf.score(X[ind_test:],y[ind_test:]))\n",
    "# print(clf.predict(X))\n",
    "# print(clf.predict_proba(X)[:,1])\n",
    "# print(y)\n",
    "plt.hist(clf.predict_proba(X)[:,1])\n",
    "plt.xlabel('False <-----                -----> True')\n",
    "plt.xlim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_P_back.n.01_back.n.01_', 0.9931448730460213),\n",
       " ('chart.n.01', -0.9255702715193995),\n",
       " ('_S_object.n.01_woman.n.01_', -0.850563876298183),\n",
       " ('_P_sit.v.01_sit.v.01_', 0.7863662008501313),\n",
       " ('_S_chart.n.01_chart.n.01_', 0.7611882310138072),\n",
       " ('_P_interaction.n.01_woman.n.01_', 0.7503006493554206),\n",
       " ('_P_stand.v.01_stand.v.01_', 0.7409931171294634),\n",
       " ('_S_object.n.01_street.n.01_', -0.7374525025471854),\n",
       " ('_S_nature.n.03_rock.n.01_', 0.6209688510636815),\n",
       " ('_P_show.v.01_show.v.01_', 0.5381890033548106),\n",
       " ('woman.n.01 stand.v.01', -0.46759722888249244),\n",
       " ('_S_art.n.01_art.n.01_', 0.4446621973329002),\n",
       " ('_S_art.n.01_woman.n.01_', 0.4216653564119358),\n",
       " ('_S_street.n.01_street.n.01_', 0.4192239891978258),\n",
       " ('_Decoration_', -0.34427919730766493),\n",
       " ('_S_object.n.01_man.n.01_', 0.3330045112415962),\n",
       " ('_P_interaction.n.01_', 0.3129498797295498),\n",
       " ('_Person_front_', 0.30575652995624225),\n",
       " ('_P_person.n.02_web.n.01_', 0.29522806141299035),\n",
       " ('_P_gesture.n.01_woman.n.01_', 0.29392875909481075),\n",
       " ('_NLayers_', -0.25810680352182974),\n",
       " ('_P_stand.v.01_be.v.01_', -0.2510435265912733),\n",
       " ('man.n.01', -0.2198886836427976),\n",
       " ('_P_interaction.n.01_chart.n.01_', -0.21428003007664356),\n",
       " ('_P_lean.v.01_lean.v.01_', 0.21127708708165402),\n",
       " ('_S_wall.n.01_hospital.n.01_', 0.1801103014261182),\n",
       " ('_S_furniture.n.01_sofa.n.01_', 0.17673387558257297),\n",
       " ('sit.v.01', -0.1644736776466591),\n",
       " ('christmas.n.01', -0.16200761625567342),\n",
       " ('_S_vehicle.n.01_airplane.n.01_', 0.14094270350802043),\n",
       " ('following.s.02', -0.12301290886216018),\n",
       " ('stand.v.01', -0.09387723133200564),\n",
       " ('man.n.01 woman.n.01', -0.05497447166130959),\n",
       " ('show.v.01 chart.n.01', -0.04329321718609969),\n",
       " ('telephone.n.01 following.s.02', -0.040975669366543926),\n",
       " ('telephone.n.01', -0.02506329310000921),\n",
       " ('male_child.n.01', -0.024298105860811547),\n",
       " ('tree.n.01', -0.021814452545452452),\n",
       " ('work.n.01', -0.019155274258026014),\n",
       " ('show.v.01 form.n.01', -0.018182622785345305),\n",
       " ('form.n.01', -0.01631536090987926),\n",
       " ('_P_sit.v.01_be.v.01_', -0.010341885368087472),\n",
       " ('screening.n.01', 0.004530557377028023),\n",
       " ('_P_occupation.n.01_', 0.004295511044972499),\n",
       " ('christmas.n.01 tree.n.01', -0.0038969795514022716),\n",
       " ('male_child.n.01 be.v.01', -0.0038491729432927986),\n",
       " ('confront.v.02', 0.003438919719214226),\n",
       " ('play.v.01 telephone.n.01', -0.003310692004738272),\n",
       " ('following.s.02 chart.n.01', -0.0022280659149125372),\n",
       " ('chart.n.01 screening.n.01', 0.0014379478906929569),\n",
       " ('work.n.01 art.n.01', -0.000840343490022872),\n",
       " ('_S_city.n.01_woman.n.01_', -0.0008190724007549073),\n",
       " ('screening.n.01 confront.v.02', 0.0007068399896041067),\n",
       " ('art.n.01', -0.00025951914897982456)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict(zip(dataset.features_, clf.coef_.tolist()[0]))\n",
    "d_filter = filter(lambda x: x[1] != 0, d.items())\n",
    "sorted(d_filter, key=lambda x: abs(x[1]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo - unseen keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2scene",
   "language": "python",
   "name": "text2scene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
