{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dataset import Dataset, DatasetReality\n",
    "from models.pipeline import prep_data, train_classifier\n",
    "from ana.visual import STAT, ROC, FEAT\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(7)\n",
    "random.seed(7)\n",
    "\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## for evaluation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Preparing data..\n",
      " - Initialize image encoder..\n",
      "  - Set feature names..\n",
      "  - Build category level idf..\n",
      "  - Build similarity normalizer..\n",
      " - Initialize text encoder..\n",
      " - Initialize joint encoder..\n",
      " - Set feature names..\n",
      "- Fetching training data..\n",
      "     Fetched - [82]\n",
      "- Fetching test data..\n",
      "     Fetched - [10]\n",
      "  - Data train shape (246, 10443)\n",
      "  - Data test shape (30, 10443)\n"
     ]
    }
   ],
   "source": [
    "# dataset, X, y, pairs, index = prep_data(Dataset, shuffle_interval=3)\n",
    "dataset = prep_data(Dataset, test=0.1, shuffle=True, seed=None,\n",
    "                    text_idf=True, categ_idf=True,\n",
    "                    cross_simi=True,\n",
    "                    norm_simi=True, suppress_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Preparing data..\n",
      " - Initialize image encoder..\n",
      "  - Set feature names..\n",
      "  - Build category level idf..\n",
      "  - Build similarity normalizer..\n",
      " - Initialize text encoder..\n",
      " - Initialize joint encoder..\n",
      " - Set feature names..\n",
      " - Build fake layers..\n",
      " - Set feature names..\n",
      "- Fetching training data..\n",
      "     Fetched - [82]\n",
      "- Fetching test data..\n",
      "     Fetched - [10]\n",
      "  - Data train shape (164, 311)\n",
      "  - Data test shape (20, 311)\n"
     ]
    }
   ],
   "source": [
    "dataset_r = prep_data(DatasetReality,\n",
    "                      index_tup=(dataset.index_train,\n",
    "                                 dataset.index_test), \n",
    "                      categ_idf=True, \n",
    "                      cross_simi=True,\n",
    "                      norm_simi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_classifier(dataset,\n",
    "                       class_weight={1: 1, 0: 0.1},\n",
    "                       C=20)\n",
    "clf_r = train_classifier(dataset_r,\n",
    "                         class_weight={1: 1, 0: 0.1},\n",
    "                         C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset.data_test[:,-1].toarray().flatten()\n",
    "y_prob = clf.predict_proba(dataset.data_test[:,:-1])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "suffix = 'temp'\n",
    "STAT(y_true, y_prob, path='STAT_%s' % suffix)\n",
    "ROC(y_true, y_prob, path='ROC_%s' % suffix)\n",
    "# FEAT(dataset, clf, path='realityFEAT_%s' % suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0] ------ 73 -----\n",
      "\n",
      "Layers:  ['A2211', 'A3211']\n",
      "Keywords:  ['landscape.n.01', 'city.n.01', 'street.n.01', 'person.n.02', 'stand.v.01', 'lean.v.01']\n",
      "Sentence: A woman looks in the window.\n",
      "Tokens: ['woman.n.01', 'look.v.01', 'window.n.01']\n",
      "Seen tokens: ['woman.n.01', 'look.v.01', 'window.n.01']\n",
      "\n",
      "Predicted layers:  ['A2113', 'A325']\n",
      "Predicted keywords: ['room.n.01', 'object.n.01', 'wall.n.01', 'person.n.02', 'gesture.n.01'] Prob: 0.994258\n",
      "Max contributed features: [('cons', '_S_wall.n.01-window.n.01_', 1.3871556681555537, 3.9477570842570873), ('cons', '_NLayers_', 2.0, 0.4814392282309747), ('real', '_P_gesture.n.01_', 0.7773747318635359, 1.185394816083373), ('real', '_S_wall.n.01_', 0.8697725664271759, -0.21221804365044694), ('real', '_NLayers_', 2.0, -0.4626998858633322), ('real', '_S_object.n.01_', 0.37501185772270385, -5.7054482876199515), ('cons', '_P_gesture.n.01_', 0.7773747318635359, -0.942456680542655)]\n",
      "Acc: 0.756757 - Precision: 0.428571 - Recall: 0.375000 - F1: 0.400000\n",
      " [1] ------ 87 -----\n",
      "\n",
      "Layers:  ['A1', 'A2114', 'A322']\n",
      "Keywords:  ['room.n.01', 'object.n.01', 'sundries.n.01', 'person.n.02', 'sit.v.01']\n",
      "Sentence: A woman holds a toy.\n",
      "Tokens: ['woman.n.01', 'keep.v.01', 'plaything.n.01']\n",
      "Seen tokens: ['woman.n.01', 'keep.v.01', 'plaything.n.01']\n",
      "\n",
      "Predicted layers:  ['A2114', 'A316']\n",
      "Predicted keywords: ['room.n.01', 'object.n.01', 'sundries.n.01', 'interaction.n.01', 'enjoyment.n.02'] Prob: 0.976724\n",
      "Max contributed features: [('cons', '_S_object.n.01-plaything.n.01_', 1.1329949090378484, 2.273362876026505), ('cons', '_NLayers_', 2.0, 0.4814392282309747), ('cons', '_P_enjoyment.n.02_', 0.516919864717888, 1.3514688603374032), ('cons', '_S_sundries.n.01_', 0.516919864717888, 0.60109999742598), ('cons', 'woman.n.01 keep.v.01', 4.725693427236653, -0.005764860932700884), ('real', '_P_enjoyment.n.02_', 0.516919864717888, -0.3887090268731789), ('cons', 'keep.v.01', 4.725693427236653, -0.04309395513742153), ('real', '_NLayers_', 2.0, -0.4626998858633322), ('cons', 'plaything.n.01', 4.725693427236653, -0.08402994687827939), ('real', '_S_object.n.01_', 0.37501185772270385, -5.7054482876199515)]\n",
      "Acc: 0.864865 - Precision: 0.714286 - Recall: 0.625000 - F1: 0.666667\n",
      " [2] ------ 15 -----\n",
      "\n",
      "Layers:  ['A1', 'A325']\n",
      "Keywords:  ['person.n.02', 'gesture.n.01']\n",
      "Sentence: A woman is showing love\n",
      "Tokens: ['woman.n.01', 'show.v.01', 'love.v.01']\n",
      "Seen tokens: ['woman.n.01', 'show.v.01']\n",
      "\n",
      "Predicted layers:  ['A1', 'A2222', 'A324']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'person.n.02', 'show.v.01'] Prob: 0.986920\n",
      "Max contributed features: [('cons', '_P_show.v.01-show.v.01_', 2.13246962109305, 1.9345187411507625), ('cons', '_NLayers_', 3.0, 0.4814392282309747), ('cons', '_Background_', 0.33728823949206993, 0.9321073281828504), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('real', '_P_show.v.01_', 0.516919864717888, -1.3295854640024007), ('real', '_Background_', 0.33728823949206993, -3.6906238884170057), ('real', '_NLayers_', 3.0, -0.4626998858633322), ('cons', 'show.v.01', 3.8094026953624978, -0.2963852038401855)]\n",
      "Acc: 0.837838 - Precision: 0.375000 - Recall: 0.750000 - F1: 0.500000\n",
      " [3] ------ 58 -----\n",
      "\n",
      "Layers:  ['A1', 'A312']\n",
      "Keywords:  ['interaction.n.01', 'abstraction.n.01']\n",
      "Sentence: A woman is standing to annotate.\n",
      "Tokens: ['woman.n.01', 'stand.v.01', 'annotate.v.01']\n",
      "Seen tokens: ['woman.n.01', 'stand.v.01']\n",
      "\n",
      "Predicted layers:  ['A1', 'A2222', 'A3211']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'person.n.02', 'stand.v.01', 'lean.v.01'] Prob: 0.989340\n",
      "Max contributed features: [('cons', '_P_stand.v.01-stand.v.01_', 0.7467785844913857, 14.969926459386711), ('cons', '_NLayers_', 3.0, 0.4814392282309747), ('cons', '_Background_', 0.33728823949206993, 0.9321073281828504), ('real', '_P_lean.v.01_', 0.705705403418576, 0.4619615027351422), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('real', '_Background_', 0.33728823949206993, -3.6906238884170057), ('real', '_NLayers_', 3.0, -0.4626998858633322), ('cons', '_P_stand.v.01_', 0.3126527571052742, -13.010002465309377), ('cons', 'stand.v.01', 2.9339339580085975, -1.4716822841796735)]\n",
      "Acc: 0.729730 - Precision: 0.222222 - Recall: 0.400000 - F1: 0.285714\n",
      " [4] ------ 24 -----\n",
      "\n",
      "Layers:  ['A1', 'A2211', 'A315']\n",
      "Keywords:  ['landscape.n.01', 'city.n.01', 'street.n.01', 'interaction.n.01', 'travel.n.01']\n",
      "Sentence: A man is riding a bike on the street.\n",
      "Tokens: ['man.n.01', 'rid.v.01', 'motorcycle.n.01', 'street.n.01']\n",
      "Seen tokens: ['man.n.01', 'rid.v.01', 'street.n.01']\n",
      "\n",
      "Predicted layers:  ['A2212', 'A316']\n",
      "Predicted keywords: ['landscape.n.01', 'city.n.01', 'building.n.01', 'interaction.n.01', 'enjoyment.n.02'] Prob: 0.939945\n",
      "Max contributed features: [('cons', '_S_building.n.01-street.n.01_', 0.9390907070984186, 2.8837988445007245), ('cons', '_NLayers_', 2.0, 0.4814392282309747), ('cons', '_P_enjoyment.n.02_', 0.516919864717888, 1.3514688603374032), ('real', '_P_enjoyment.n.02_', 0.516919864717888, -0.3887090268731789), ('real', '_NLayers_', 2.0, -0.4626998858633322), ('real', '_S_city.n.01_', 0.6471472982907119, -5.54052241263086), ('cons', 'street.n.01', 4.320228319128488, -0.2678446577413387)]\n",
      "Acc: 0.864865 - Precision: 0.714286 - Recall: 0.625000 - F1: 0.666667\n",
      " [5] ------ 84 -----\n",
      "\n",
      "Layers:  ['A1', 'A2122', 'A312']\n",
      "Keywords:  ['room.n.01', 'abstraction.n.01', 'art.n.01', 'interaction.n.01', 'abstraction.n.01']\n",
      "Sentence: A woman sat to rest.\n",
      "Tokens: ['woman.n.01', 'sit.v.01', 'rest.v.01']\n",
      "Seen tokens: ['woman.n.01', 'sit.v.01', 'rest.v.01']\n",
      "\n",
      "Predicted layers:  ['A2222', 'A322']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'person.n.02', 'sit.v.01'] Prob: 0.996018\n",
      "Max contributed features: [('cons', '_P_sit.v.01-sit.v.01_', 2.0883568457587343, 2.0493794686659275), ('cons', 'woman.n.01 sit.v.01', 3.627081138568543, 0.31221586315759664), ('cons', 'sit.v.01 rest.v.01', 4.725693427236653, 0.2085107175845557), ('cons', '_NLayers_', 2.0, 0.4814392282309747), ('cons', 'rest.v.01', 4.725693427236653, 0.04830218553389089), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('cons', 'sit.v.01', 3.2216160304603783, 0.0028751120646252257), ('real', '_NLayers_', 2.0, -0.4626998858633322), ('cons', '_P_sit.v.01_', 0.705705403418576, -3.0326802405465636)]\n",
      "Acc: 0.702703 - Precision: 0.285714 - Recall: 0.250000 - F1: 0.266667\n",
      " [6] ------ 68 -----\n",
      "\n",
      "Layers:  ['A1', 'A2222', 'A325', 'A4']\n",
      "Keywords:  ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'person.n.02', 'gesture.n.01']\n",
      "Sentence: A man and a woman get married.\n",
      "Tokens: ['man.n.01', 'woman.n.01', 'get.n.01', 'marry.v.01']\n",
      "Seen tokens: ['man.n.01', 'woman.n.01']\n",
      "\n",
      "Predicted layers:  ['A1', 'A2222', 'A316']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'interaction.n.01', 'enjoyment.n.02'] Prob: 0.954878\n",
      "Max contributed features: [('cons', '_NLayers_', 3.0, 0.4814392282309747), ('cons', '_P_enjoyment.n.02_', 0.516919864717888, 1.3514688603374032), ('cons', 'man.n.01 woman.n.01', 3.339399066116762, 0.13630969474949683), ('cons', '_Background_', 0.33728823949206993, 0.9321073281828504), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('real', '_P_enjoyment.n.02_', 0.516919864717888, -0.3887090268731789), ('real', '_Background_', 0.33728823949206993, -3.6906238884170057), ('real', '_NLayers_', 3.0, -0.4626998858633322)]\n",
      "Acc: 0.864865 - Precision: 0.750000 - Recall: 0.666667 - F1: 0.705882\n",
      " [7] ------ 26 -----\n",
      "\n",
      "Layers:  ['A2121', 'A325', 'A4']\n",
      "Keywords:  ['room.n.01', 'abstraction.n.01', 'chart.n.01', 'person.n.02', 'gesture.n.01']\n",
      "Sentence: A woman is showing two charts.\n",
      "Tokens: ['woman.n.01', 'show.v.01', 'two.n.01', 'chart.n.01']\n",
      "Seen tokens: ['woman.n.01', 'show.v.01', 'two.n.01', 'chart.n.01']\n",
      "\n",
      "Predicted layers:  ['A2121', 'A324']\n",
      "Predicted keywords: ['room.n.01', 'abstraction.n.01', 'chart.n.01', 'person.n.02', 'show.v.01'] Prob: 0.995998\n",
      "Max contributed features: [('cons', '_S_chart.n.01-chart.n.01_', 0.7840279861320123, 8.475697855441014), ('cons', '_P_show.v.01-show.v.01_', 2.13246962109305, 1.9345187411507625), ('cons', '_NLayers_', 2.0, 0.4814392282309747), ('real', '_P_show.v.01_', 0.516919864717888, -1.3295854640024007), ('real', '_NLayers_', 2.0, -0.4626998858633322), ('cons', 'show.v.01', 3.8094026953624978, -0.2963852038401855), ('cons', 'chart.n.01', 2.9339339580085975, -1.6463471980956068)]\n",
      "Acc: 0.918919 - Precision: 0.875000 - Recall: 0.777778 - F1: 0.823529\n",
      " [8] ------ 69 -----\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  ['A1', 'A2222', 'A316']\n",
      "Keywords:  ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'interaction.n.01', 'enjoyment.n.02']\n",
      "Sentence: A woman puts up a lantern.\n",
      "Tokens: ['woman.n.01', 'put.v.01', 'lantern.n.01']\n",
      "Seen tokens: ['woman.n.01', 'put.v.01']\n",
      "\n",
      "Predicted layers:  ['A2222', 'A316', 'A4']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'interaction.n.01', 'enjoyment.n.02'] Prob: 0.938101\n",
      "Max contributed features: [('cons', '_NLayers_', 3.0, 0.4814392282309747), ('cons', '_Decoration_', 1.0, 0.9093219472313856), ('cons', '_P_enjoyment.n.02_', 0.516919864717888, 1.3514688603374032), ('cons', 'put.v.01', 4.725693427236653, 0.015923794596434563), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('real', '_P_enjoyment.n.02_', 0.516919864717888, -0.3887090268731789), ('real', '_NLayers_', 3.0, -0.4626998858633322), ('real', '_Decoration_', 1.0, -3.3624135558676054)]\n",
      "Acc: 0.945946 - Precision: 0.875000 - Recall: 0.875000 - F1: 0.875000\n",
      " [9] ------ 48 -----\n",
      "\n",
      "Layers:  ['A1', 'A314']\n",
      "Keywords:  ['interaction.n.01', 'sociable.n.01']\n",
      "Sentence: A man and a woman are transferring money.\n",
      "Tokens: ['man.n.01', 'woman.n.01', 'transfer.v.01', 'money.n.01']\n",
      "Seen tokens: ['man.n.01', 'woman.n.01', 'money.n.01']\n",
      "\n",
      "Predicted layers:  ['A1', 'A2222', 'A316']\n",
      "Predicted keywords: ['landscape.n.01', 'nature.n.03', 'wild.n.01', 'interaction.n.01', 'enjoyment.n.02'] Prob: 0.957963\n",
      "Max contributed features: [('cons', '_NLayers_', 3.0, 0.4814392282309747), ('cons', '_P_enjoyment.n.02_', 0.516919864717888, 1.3514688603374032), ('cons', 'man.n.01 woman.n.01', 3.339399066116762, 0.13630969474949683), ('cons', '_Background_', 0.33728823949206993, 0.9321073281828504), ('cons', 'money.n.01', 4.725693427236653, 0.017317281761036873), ('real', '_S_wild.n.01_', 0.2769292664318228, 0.9806634234701077), ('real', '_P_enjoyment.n.02_', 0.516919864717888, -0.3887090268731789), ('real', '_Background_', 0.33728823949206993, -3.6906238884170057), ('real', '_NLayers_', 3.0, -0.4626998858633322)]\n",
      "Acc: 0.837838 - Precision: 0.375000 - Recall: 0.750000 - F1: 0.500000\n",
      "mean F1: 0.569013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5690126050420168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model import Discriminator, categMetric\n",
    "discriminator = Discriminator(dataset, clf, dataset_r, clf_r)\n",
    "categMetric(discriminator, lamb=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for s in wn.synsets('landscape'):\n",
    "    print(s, s.definition())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2scene",
   "language": "python",
   "name": "text2scene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
