{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from scipy import sparse\n",
    "\n",
    "from tools.text_process import TfidfEncoder\n",
    "from tools.image_process import getLayerNames, CategEncoder\n",
    "from tools.joint_process import SimiEncoder\n",
    "\n",
    "# random image generator, subject to rules\n",
    "from tools.generator import ranGenLayer\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, img_dir='images', txt_dir='text'):\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_dir = txt_dir\n",
    "        \n",
    "        # fitting the vectorizer will process all the text\n",
    "        # so we have double processed the text here\n",
    "        self.img_encoder = CategEncoder()\n",
    "        self.txt_encoder = TfidfEncoder()\n",
    "        self.joint_encoder = SimiEncoder(self.img_encoder,\n",
    "                                         self.txt_encoder)\n",
    "        \n",
    "        # set features\n",
    "        self.features_ = []\n",
    "        self.features_.extend(self.txt_encoder.vocab_)\n",
    "        self.features_.extend(self.img_encoder.features_)\n",
    "        self.features_.extend(self.joint_encoder.features_)\n",
    "      \n",
    "    def getOneLayerSent(self, txt_name=None, img_name=None,\n",
    "                              ran_txt=False, ran_img=False,\n",
    "                              fake_img=False):\n",
    "        ##### preprocess\n",
    "        ## text\n",
    "        if ran_txt:\n",
    "            all_txt = glob.glob(self.txt_dir+'/*.txt')\n",
    "            # rule out current text\n",
    "            all_txt.remove(txt_name)\n",
    "            txt_name = random.choice(all_txt)\n",
    "        else:\n",
    "            assert(txt_name)\n",
    "            \n",
    "        with open(txt_name, 'r') as f:\n",
    "            sent = f.read()\n",
    "            \n",
    "        ## image\n",
    "        if ran_img:\n",
    "            assert img_name\n",
    "            assert not fake_img\n",
    "            all_img = glob.glob(self.img_dir+'/*.svg')\n",
    "            all_img.remove(img_name)\n",
    "            img_name = random.choice(all_img)\n",
    "            layers = getLayerNames(img_name)\n",
    "        elif fake_img:\n",
    "            assert img_name is None\n",
    "            assert not ran_img\n",
    "            layers = ranGenLayer()\n",
    "        else:\n",
    "            layers = getLayerNames(img_name)\n",
    "            \n",
    "        return layers, sent\n",
    "        \n",
    "    def __getEmbed(self, **kwargs):\n",
    "        \n",
    "        layers, sent = self.getOneLayerSent(**kwargs)\n",
    "        \n",
    "        # tofeature\n",
    "        txt_embed = self.txt_encoder.encode(sent)\n",
    "        img_embed = self.img_encoder.encode(layers)\n",
    "        joint_embed = self.joint_encoder.encode(layers, sent)\n",
    "        \n",
    "        return np.hstack([txt_embed, img_embed, joint_embed])        \n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        img_name = '%s/%i.svg' % (self.img_dir, ind+1)\n",
    "        txt_name = '%s/%i.txt' % (self.txt_dir, ind+1)\n",
    "        \n",
    "        # triplets\n",
    "        triplets = []\n",
    "        # true match\n",
    "        triplets.append(self.__getEmbed(txt_name=txt_name,\n",
    "                                        img_name=img_name))\n",
    "#         # fake image\n",
    "#         triplets.append(self.__getEmbed(txt_name=txt_name,\n",
    "#                                         fake_img=True))\n",
    "        # mismatched text\n",
    "        triplets.append(self.__getEmbed(img_name=img_name,\n",
    "                                        txt_name=txt_name,\n",
    "                                        ran_txt=True))\n",
    "        # mismatched image\n",
    "        triplets.append(self.__getEmbed(img_name=img_name,\n",
    "                                        txt_name=txt_name,\n",
    "                                        ran_img=True))\n",
    "        \n",
    "        xs = np.vstack(triplets)\n",
    "        \n",
    "        # ys\n",
    "        # ys = np.array([1,0,0,0]).reshape(-1,1)\n",
    "        ys = np.array([1,0,0]).reshape(-1,1)\n",
    "        \n",
    "        return sparse.csr_matrix(np.hstack([xs, ys]))\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(glob.glob(self.img_dir+'/*.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: sideways with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: grid with tag a does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: cell with tag r does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: something with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: web with tag a does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: selfie with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features:  11430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: grid with tag a does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: sideways with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: web with tag a does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/image_process.py:42: UserWarning: In file images/43.svg layer A1 not at the same level with the first layer! Skip it!\n",
      "  warnings.warn('In file %s layer %s not at the same level with the first layer! Skip it!' % (file, layer.getAttribute('id')))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/image_process.py:42: UserWarning: In file images/43.svg layer A2222 not at the same level with the first layer! Skip it!\n",
      "  warnings.warn('In file %s layer %s not at the same level with the first layer! Skip it!' % (file, layer.getAttribute('id')))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/image_process.py:42: UserWarning: In file images/43.svg layer A323 not at the same level with the first layer! Skip it!\n",
      "  warnings.warn('In file %s layer %s not at the same level with the first layer! Skip it!' % (file, layer.getAttribute('id')))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: cell with tag r does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n",
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: something with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (276, 11431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongjustin/Documents/Text2Scene/Text2Scene/tools/text_process.py:48: UserWarning: selfie with tag n does not belong to any synsets.\n",
      "  warnings.warn('%s with tag %s does not belong to any synsets.' % (lemma, tag))\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "print('# features: ', len(dataset.features_))\n",
    "data = sparse.vstack([dataset[i] for i in range(len(dataset))])\n",
    "X, y = data[:,:-1], data[:,-1]\n",
    "y = y.toarray().flatten()\n",
    "print('data shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2112', 'A311']\n",
      "['indoor.a.01', 'object.n.01', 'appliance.n.02', 'interaction.n.01', 'occupation.n.01']\n",
      "A man looks at his chart with his back.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('_S_object.n.01_back.n.01_', 1.845826690498331),\n",
       " ('_S_object.n.01_chart.n.01_', 1.6916760106710724),\n",
       " ('_S_object.n.01_man.n.01_', 1.845826690498331),\n",
       " ('_S_appliance.n.02_back.n.01_', 1.1526795099383855),\n",
       " ('_S_appliance.n.02_chart.n.01_', 1.072636802264849),\n",
       " ('_S_appliance.n.02_man.n.01_', 1.2396908869280152),\n",
       " ('_P_interaction.n.01_back.n.01_', 1.1526795099383855),\n",
       " ('_P_interaction.n.01_chart.n.01_', 1.4403615823901665),\n",
       " ('_P_interaction.n.01_man.n.01_', 1.1526795099383855),\n",
       " ('_P_occupation.n.01_back.n.01_', 1.1526795099383855),\n",
       " ('_P_occupation.n.01_chart.n.01_', 1.4403615823901665),\n",
       " ('_P_occupation.n.01_man.n.01_', 1.1526795099383855)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers, sentence = dataset.getOneLayerSent(txt_name='text/1.txt',\n",
    "                                       img_name='images/6.svg')\n",
    "print(layers)\n",
    "print(dataset.img_encoder.layer2keyword(layers))\n",
    "print(sentence)\n",
    "list(filter(lambda x: x[1]!=0, zip(dataset.joint_encoder.features_, dataset.joint_encoder.encode(layers, sentence))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train:  248\n",
      "# test:  28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(# random_state=0,\n",
    "                         solver='liblinear',\n",
    "                         # class_weight={1: 1, 0:0.5},\n",
    "                         penalty='l1', #'l2' use l1 to learn sparsely\n",
    "                         C=1.0,\n",
    "                         max_iter=100)\n",
    "\n",
    "ind_test = int(X.shape[0] * 0.9)\n",
    "print('# train: ', ind_test)\n",
    "print('# test: ', X.shape[0] - ind_test)\n",
    "clf.fit(X[:ind_test], y[:ind_test])\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Accuracy: ', clf.score(X[ind_test:],y[ind_test:]))\n",
    "# print(clf.predict(X))\n",
    "# print(clf.predict_proba(X)[:,1])\n",
    "# print(y)\n",
    "plt.hist(clf.predict_proba(X)[:,1])\n",
    "plt.xlabel('False <-----                -----> True')\n",
    "plt.xlim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_P_occupation.n.01_office.n.01_', 2.1182754617128965),\n",
       " ('_S_chart.n.01_chart.n.01_', 1.5746809528077048),\n",
       " ('_S_nature.n.03_park.n.01_', 1.3927423204325147),\n",
       " ('_P_gesture.n.01_man.n.01_', 1.2178153000298388),\n",
       " ('_P_back.n.01_back.n.01_', 1.098497248883695),\n",
       " ('_S_chart.n.01_woman.n.01_', -1.0835089258903299),\n",
       " ('_P_stand.v.01_stand.v.01_', 0.9873846747466464),\n",
       " ('_S_street.n.01_street.n.01_', 0.8431317364881235),\n",
       " ('_P_person.n.02_', -0.828524968284093),\n",
       " ('_S_art.n.01_art.n.01_', 0.7618194652897353),\n",
       " ('_S_furniture.n.01_sofa.n.01_', 0.7272672130388853),\n",
       " ('chart.n.01', -0.6804585596605586),\n",
       " ('_S_nature.n.03_rock.n.01_', 0.6560195744777696),\n",
       " ('_S_chart.n.01_icon.n.01_', 0.6461943786632907),\n",
       " ('_P_enjoyment.n.02_movie.n.01_', 0.6390235046982004),\n",
       " ('stand.v.01 look.v.01', -0.6339595596037849),\n",
       " ('_P_person.n.02_woman.n.01_', 0.5900937984767101),\n",
       " ('plaything.n.01', -0.5544031892819519),\n",
       " ('_P_show.v.01_be.v.01_', 0.5287155588248746),\n",
       " ('_S_nature.n.03_computer.n.01_', -0.5014375385748455),\n",
       " ('_P_sit.v.01_sit.v.01_', 0.49559500655938726),\n",
       " ('stand.v.01', -0.4684098673032515),\n",
       " ('_P_stand.v.01_walk.v.01_', -0.3860617513592138),\n",
       " ('_P_person.n.02_movie.n.01_', -0.36613094605798113),\n",
       " ('_P_emotion.n.01_man.n.01_', 0.3660600736156267),\n",
       " ('_P_sociable.n.01_', -0.34474717555742773),\n",
       " ('_S_nature.n.03_man.n.01_', 0.2701689271663092),\n",
       " ('sit.v.01 computer.n.01', 0.2689503826311505),\n",
       " ('park.n.01', -0.26143473404906337),\n",
       " ('stand.v.01 earth.n.01', 0.26063447095325604),\n",
       " ('_Person_', -0.24959305198439136),\n",
       " ('show.v.01 two.n.01', -0.24712688915571332),\n",
       " ('_P_stand.v.01_sit.v.01_', -0.24207497561634844),\n",
       " ('_S_nature.n.03_camera.n.01_', 0.234834863008379),\n",
       " ('walk.v.01 look.v.01', 0.2284233548569763),\n",
       " ('_S_art.n.01_', -0.22421500209855824),\n",
       " ('_P_occupation.n.01_computer.n.01_', 0.2026866014976851),\n",
       " ('_S_park.n.02_park.n.01_', 0.20252521401522827),\n",
       " ('_S_wild.n.01_money.n.01_', -0.2017276256871009),\n",
       " ('_S_nature.n.03_window.n.01_', -0.2014067110247275),\n",
       " ('_P_interaction.n.01_woman.n.01_', 0.19903953785693626),\n",
       " ('screening.n.01', -0.19677782811992708),\n",
       " ('_S_object.n.01_woman.n.01_', -0.1880367550972602),\n",
       " ('woman.n.01 sit.v.01', -0.17556817109647901),\n",
       " ('_S_wall.n.01_window.n.01_', 0.16611830122038088),\n",
       " ('confront.v.02', -0.15778574789723154),\n",
       " ('discourse.v.01', -0.15279584887074243),\n",
       " ('earth.n.01', 0.14984221888302873),\n",
       " ('screening.n.01 confront.v.02', -0.1386615706220701),\n",
       " ('be.v.01 sit.v.01', 0.13117280266744388),\n",
       " ('_P_enjoyment.n.02_work.n.01_', -0.1302207177885985),\n",
       " ('_S_vehicle.n.01_airplane.n.01_', 0.12740099651324324),\n",
       " ('_S_object.n.01_', 0.12615079964438475),\n",
       " ('_P_stand.v.01_be.v.01_', -0.12136942976795771),\n",
       " ('_NLayers_', -0.11857256096346996),\n",
       " ('walk.v.01', 0.11640504126861802),\n",
       " ('_P_in_front_of_S_', -0.11378932810082362),\n",
       " ('_S_art.n.01_man.n.01_', 0.11269609285828512),\n",
       " ('sit.v.01 office.n.01', -0.10918716140774969),\n",
       " ('look.v.01', 0.10914049473840014),\n",
       " ('watch.v.01 picture.n.01', 0.09979289120354533),\n",
       " ('two.n.01 chart.n.01', -0.09536091751665192),\n",
       " ('_P_sport.n.01_woman.n.01_', 0.09439794543569684),\n",
       " ('rid.v.01 motorcycle.n.01', -0.08854601503648189),\n",
       " ('_P_person.n.02_computer.n.01_', -0.08658045607099593),\n",
       " ('street.n.01', -0.08068420868574956),\n",
       " ('be.v.01', 0.07755052402837784),\n",
       " ('motorcycle.n.01 street.n.01', -0.0773734138842363),\n",
       " ('motorcycle.n.01', -0.07733946716243953),\n",
       " ('hot.a.01', 0.0771515789153851),\n",
       " ('be.v.01 correct.v.01', -0.07698991160308885),\n",
       " ('_S_building.n.01_woman.n.01_', -0.07520270330371844),\n",
       " ('_P_abstraction.n.01_', -0.0751545472540026),\n",
       " ('_Decoration_', 0.06341384862917974),\n",
       " ('stand.v.01 computer.n.01', -0.06126997777458807),\n",
       " ('car.n.01', 0.06047313013862984),\n",
       " ('_P_show.v.01_sit.v.01_', -0.04967247221213977),\n",
       " ('doctor.n.01 be.v.01', 0.04507651296648152),\n",
       " ('be.v.01 lean.v.01', 0.04500953496721768),\n",
       " ('hot.a.01 air.n.01', 0.04463607850033114),\n",
       " ('hallmark.n.01', 0.041248859552424334),\n",
       " ('night.n.01', 0.04007749753185991),\n",
       " ('make.v.01 weather.n.01', 0.038772888543291854),\n",
       " ('sit.v.01 land.n.04', 0.036639959849230005),\n",
       " ('play.v.01', -0.036444070567882826),\n",
       " ('two.n.01', -0.03384327997078059),\n",
       " ('doctor.n.01', 0.03288239061501726),\n",
       " ('christmas.n.01 tree.n.01', -0.031828261410387464),\n",
       " ('write.v.01 hospital.n.01', 0.031448389728260875),\n",
       " ('air.n.01', 0.029648532023352752),\n",
       " ('female.a.01 shopping.n.01', -0.027309786440709836),\n",
       " ('be.v.01 lie.v.01', -0.02730656987676231),\n",
       " ('report.n.01', 0.02498502395458817),\n",
       " ('pull.v.01', -0.023589017804298687),\n",
       " ('be.v.01 clean.v.01', -0.023535045921368115),\n",
       " ('airplane.n.01', -0.023160916129637072),\n",
       " ('annotate.v.01', 0.0209618540663342),\n",
       " ('work.v.01 night.n.01', 0.020352256659881822),\n",
       " ('stand.v.01 annotate.v.01', 0.020288430196767668),\n",
       " ('woman.n.01 play.n.01', 0.020146367746238545),\n",
       " ('correct.v.01', -0.019938052756310266),\n",
       " ('rid.v.01 hot.a.01', 0.019663781572812032),\n",
       " ('edge.n.01', -0.016949298218154763),\n",
       " ('about.r.03 person.n.01', 0.016619037302054676),\n",
       " ('clean.v.01', -0.016523689175863852),\n",
       " ('woman.n.01 stand.v.01', -0.016110657027761738),\n",
       " ('look.v.01 chart.n.01', 0.015751406844725487),\n",
       " ('document.n.01', -0.014937779416293252),\n",
       " ('center.n.01', 0.014862723600796606),\n",
       " ('_P_stand.v.01_watch.v.01_', 0.0129017005351568),\n",
       " ('be.v.01 three.n.01', 0.012393668142957096),\n",
       " ('lie.v.01', -0.012380613310647026),\n",
       " ('correct.v.01 document.n.01', -0.011988827444341939),\n",
       " ('about.r.03', 0.01196138025501104),\n",
       " ('person.n.01', 0.011604283142888345),\n",
       " ('use.v.01', 0.01115795739403413),\n",
       " ('pull.v.01 sword.n.01', -0.010636892380238013),\n",
       " ('lean.v.01 car.n.01', 0.010501178906697089),\n",
       " ('hospital.n.01', 0.010471453014377777),\n",
       " ('hallmark.n.01 about.r.03', 0.009793546612435578),\n",
       " ('be.v.01 show.v.01', -0.009529179100660664),\n",
       " ('turbine.n.01', -0.007876209356386542),\n",
       " ('lantern.n.01', 0.007638847612376812),\n",
       " ('write.v.01', 0.007234663224697861),\n",
       " ('put.v.01 up.r.01', 0.006380765423747605),\n",
       " ('be.v.01 write.v.01', 0.006352561990875123),\n",
       " ('sword.n.01', -0.006051608625906364),\n",
       " ('lie.v.01 sofa.n.01', -0.005760490735891831),\n",
       " ('sofa.n.01', -0.005450693415650765),\n",
       " ('_S_abstraction.n.01_', -0.004742428019919735),\n",
       " ('back.n.01', 0.004663954910109126),\n",
       " ('chart.n.01 back.n.01', 0.0044328425170198),\n",
       " ('compass.n.01', 0.004369191118480775),\n",
       " ('chart.n.01 screening.n.01', -0.004105276964181207),\n",
       " ('man.n.01 look.v.01', 0.0032547941322510162),\n",
       " ('_P_occupation.n.01_work_force.n.01_', -0.0032306917537726987),\n",
       " ('three.n.01 hallmark.n.01', 0.0026434859754626027),\n",
       " ('play.n.01 circle.n.01', 0.002100778520332442),\n",
       " ('sword.n.01 rock.n.01', -0.0020554306738664297),\n",
       " ('circle.n.01', 0.0015934934519605986),\n",
       " ('woman.n.01 center.n.01', 0.001387705650337646),\n",
       " ('picture.n.01', 0.0013070269641931545),\n",
       " ('weather.n.01 report.n.01', 0.0011950231497106895),\n",
       " ('use.v.01 computer.n.01', 0.0006746999669507833),\n",
       " ('man.n.01 pull.v.01', -0.0006735858469029935),\n",
       " ('be.v.01 use.v.01', 0.0004344597141975329),\n",
       " ('up.r.01', 0.0003816742179929169),\n",
       " ('center.n.01 page.n.01', 0.00033784315334478435),\n",
       " ('_S_object.n.01_airport.n.01_', 0.00016811452339052056),\n",
       " ('up.r.01 lantern.n.01', 0.00010620217968053004),\n",
       " ('past.n.01 wind.n.01', -5.6040831466970035e-05),\n",
       " ('clean.v.01 computer.n.01', -2.4204510276707387e-05),\n",
       " ('woman.n.01 put.v.01', 2.3605193571648424e-05),\n",
       " ('weather.n.01', 1.8577538952669936e-05),\n",
       " ('circle.n.01 compass.n.01', 1.824042073796705e-05),\n",
       " ('wind.n.01', -7.241660580603651e-06),\n",
       " ('land.n.04', 4.0430218476384784e-06),\n",
       " ('discourse.v.01 page.n.01', -1.115044684327053e-06)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict(zip(dataset.features_, clf.coef_.tolist()[0]))\n",
    "d_filter = filter(lambda x: x[1] != 0, d.items())\n",
    "sorted(d_filter, key=lambda x: abs(x[1]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo - unseen keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brutal-force search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.generator import getAllLayerCombs\n",
    "all_layers = getAllLayerCombs()\n",
    "assert(len(all_layers) == 11*4+13*4+11*13*4*2)\n",
    "from tools.image_process import checkLayerNames\n",
    "for layer in all_layers:\n",
    "    checkLayerNames(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2scene",
   "language": "python",
   "name": "text2scene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
